name: Scrape LTC Node

on:
  repository_dispatch:
    types:
      - ltc
  schedule:
    - cron: '05 22 * * *'

defaults:
  run:
     working-directory: data-collection-scripts/ltc-scrapers/playwright-scrapers

jobs:
  scrape:
      runs-on: ubuntu-18.04
      strategy:
        fail-fast: false
        matrix:
          state: [nv, wv]
      steps:
        - uses: actions/checkout@v2
        - uses: actions/cache@v2
          with:
            path: ~/.npm
            key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
            restore-keys: |
              ${{ runner.os }}-node-
        - name: Use Node.js
          uses: actions/setup-node@v1
          with:
            node-version: '14.x'
        - name: Install dependencies
          run: npm install
        # there's an extremely irritating DNS bug somewhere (https://github.com/actions/virtual-environments/issues/798)
        # and swapping out the resolver is a weird workaround. Otherwise, app.powerbigov.us won't resolve
        - name: DNS nonsense
          run: sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf
        - name: Run scraper
          run: |
            node ${{ matrix.state }}_ltc_scraper.js > ../../../data/ltc_states/ltc_${{ matrix.state }}.csv
        - name: Commit
          if: github.ref == 'refs/heads/master'
          uses: EndBug/add-and-commit@v5
          with:
            message: Updating scraped LTC data
            add: data/ltc_states/ltc_${{ matrix.state }}.csv
            author_name: GitHub Actions
            author_email: actions@github.com
          env:
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        - name: Archive production artifacts
          uses: actions/upload-artifact@v2
          with:
            name: Video
            path: |
              data-collection-scripts/ltc-scrapers/playwright-scrapers/videos/*
            retention-days: 10
